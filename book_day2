<머신러닝의 흐름>

1. 데이터 수집
2. 데이터 가공
- 어떠한 특징을 활용할지
- 어떤 형식으로 가공해야 할지
3. 데이터 학습
- 학습 방법 선택 (알고리즘 : SVM, 랜덤포레스트, k-means)
- 매개 변수 조정 (알고리즘에 맞게 매개변수 지정)
- 모델 학습
4. 모델평가 (테스트 데이터 사용)

정밀도가 제대로 나온다면 성공. 아니라면 데이터 학습 과정을 조정


<머신러닝의 응용 분야>

1. 클래스 분류 (스팸 메일 분퓨, 필기 인식, 증권 사기)
2. 클러스터링 - 그룹나누기 (사용자의 취향을 그룹으로 묶어 사용자 취향에 맞는 광고 제공)
3. 추천 (사용자가 인터넷 서점에서 구매한 책들을 기반으로 다른 책 추천)
4. 회귀 (판매 예측, 주가 변동 등을 예측)
5. 차원 축소 (데이터 특성을 유지하면서 데이터 양 줄이기, 데이터를 시각화 하거나 구조를 추출해서 용량을 줄여 계산을 빠르게 하거나 메모리를 절약할 때 사용)


<깃허브에서 데이터 다운>
CSV 형식으로 내려받기
- 데이터 위에 RAW버튼 오른쪽클릭


<데이터마다의 분포를 그래프로 확인하기>
import matplotlib.pyplot as plt #수학전용 라이브러리 NumPy와 함께 사용하는 그래프 그리기 라이브러리
import pandas as pd #데이터 분석해주는 라이브러리
import json

# 알파벳 출현 빈도 데이터 읽어 들이기 --- (※1)
with open("./lang/freq.json", "r", encoding="utf-8") as fp:
    freq = json.load(fp)
# 언어마다 계산하기 --- (※2)
lang_dic = {}
for i, lbl in enumerate(freq[0]["labels"]):
    fq = freq[0]["freqs"][i]
    if not (lbl in lang_dic):
        lang_dic[lbl] = fq
        continue
    for idx, v in enumerate(fq):
        lang_dic[lbl][idx] = (lang_dic[lbl][idx] + v) / 2
# Pandas의 DataFrame에 데이터 넣기 --- (※3)
asclist = [[chr(n) for n in range(97,97+26)]]
df = pd.DataFrame(lang_dic, index=asclist)
# 그래프 그리기 --- (※4)
plt.style.use('ggplot')
df.plot(kind="bar", subplots=True, ylim=(0,0.15))
plt.savefig("lang-plot.png")

plt.style.use('ggplot')
df.plot(kind="line")
plt.show()


<서포트 벡터 머신(SVM)>
선을 구성하는 매개변수를 조정해서 요소들을 구분하는 선을 찾고, 이를 기반으로 패턴을 인식하는 방법
A와 B라는 두 가지 패턴이 있을 때 A와 B라는 패턴을 구분하는 방법을 찾는 것이 목표
A와 B를 벡터로 나타내서 평면 위에 올리고 구분선을 그린다.
이때 패턴의 경계가 되는 것을 "식별 평면"이라고 한다.

구분선을 확실하게 정할 수 있으면 이후에 새로운 패턴이 나타났을 때도 쉽게 분류할 수 있다.

선을 정할 때 식별 평면에서 패턴들과의 거리(마진)를 최대로 만드는 것이 가장 좋은 결과
: SVM의 마진 최대화 라는 방침


<랜덤 포레스트>
집단 학습을 기반으로 고정밀 분류, 회귀, 클러스터링 
train데이터로 다수의 의사결정트리를 만들고 이를 기반으로 다수결로 결과를 유도하여 높은 정밀도 자랑

디시젼 트리 : 트리 구조를 하고 있는 그래프, 예측 분류를 수행하는 알고리즘 자체를 부르기도 함.






